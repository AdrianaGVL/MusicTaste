{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Regression Machine Learning Methods\n",
    "The aim is to predict the energy of the songs using as input the Mel Frequency Cepstral Coefficients."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb6e75e3217a822"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b564a9330d06f0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset path and needed parameters\n",
    "Be careful and change the paths before executing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ffc0840e2f9fe9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data\n",
    "# Dataset for classification purposes\n",
    "rdata_path = 'df_energy.csv'\n",
    "\n",
    "# Parameters\n",
    "plots = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea7b8486f2deeea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data loading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65b96e7716942de0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv(rdata_path, sep=';', decimal=\",\", index_col=None)\n",
    "y = data.iloc[:, 6:7]\n",
    "X = data.iloc[:, 7:28]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "957d62300c052c7e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models\n",
    "The classification models available in this project are:\n",
    "1. Ridge regression\n",
    "2. K-Nearest Neighbours (KNN)\n",
    "3. Regression Tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b13d2324cc3b6ee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ridge Regression\n",
    "Step-by-step Ridge regression process:\n",
    "1. Load the data\n",
    "2. Execute the cross validation method over the data\n",
    "3. Define the model and its possible alphas\n",
    "5. Train the models and return the best one\n",
    "6. Test the model and save the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bdb9ad0b8292c97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Result list\n",
    "outer_results = list()\n",
    "\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# Outer loop\n",
    "for train, test in cv_outer.split(data.iloc[:, 6:28]):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train, 0:28], X.iloc[test, 0:28]\n",
    "    y_train, y_test = y.iloc[train], y.iloc[test]\n",
    "\n",
    "    # Model selection\n",
    "    model = RidgeCV(alphas=[0.1, 0.3, 0.5, 0.7, 1])\n",
    "\n",
    "    # Search\n",
    "    result = model.fit(X_train, y_train)\n",
    "\n",
    "    # Model Evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Store result\n",
    "    outer_results.append({'Model': 'Ridge', 'MSE': mse, 'R2': r2})\n",
    "\n",
    "    # Plot results\n",
    "    if plots:\n",
    "        plt.clf()\n",
    "        plt.plot([min(np.array(y_test)), max(np.array(y_test))], [min(y_pred), max(y_pred)], linestyle='--',\n",
    "                 color='black',\n",
    "                 label='Perfect Prediction')\n",
    "        plt.scatter(y_test, y_pred, color='purple')\n",
    "        plt.xlabel('Real Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title('Scatter Matrix - Ridge Regression')\n",
    "        plt.savefig(f'Ridge/Alpha_{r2}.png')\n",
    "\n",
    "    # # Report progress\n",
    "    print('- mse=%.3f,r2=%.3f, alpha=%.3f' % (mse, r2, model.alpha_,))\n",
    "\n",
    "# Summarize the estimated performance of the model\n",
    "mse_values = [item['MSE'] for item in outer_results]\n",
    "r2_values = [item['R2'] for item in outer_results]\n",
    "print('MSE: %.3f (%.3f)' % (mean(mse_values), std(mse_values)))\n",
    "print('R2: %.3f (%.3f)' % (mean(r2_values), std(r2_values)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbfc21f8e45a40a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-Nearest Neighbours (KNN)\n",
    "Step-by-step Ridge regression process:\n",
    "1. Load the data\n",
    "2. Execute the cross validation method over the data\n",
    "3. Define the model and its space\n",
    "4. Apply the search definition for the cross validation\n",
    "5. Train the models and return the best one\n",
    "6. Test the model and save the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28ab5a5f6d1f4818"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Result list\n",
    "outer_results = list()\n",
    "\n",
    "# Other variables\n",
    "num_knn = 0\n",
    "\n",
    "# Enumerate the splits\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# Outer loop\n",
    "for train, test in cv_outer.split(data.iloc[:, 6:28]):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train, 0:20].astype(float), X.iloc[test, 0:20].astype(float)\n",
    "    a1 = X_train.dtypes\n",
    "    a2 = X_test.dtypes\n",
    "    y_train, y_test = y.iloc[train].astype(float), y.iloc[test].astype(float)\n",
    "    a3 = y_train.dtypes\n",
    "    a4 = y_test.dtypes\n",
    "\n",
    "    # Configure the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "    # Model selection and search space definition\n",
    "    # Model selection\n",
    "    model = KNeighborsRegressor()\n",
    "    # Search Variables definition\n",
    "    space = dict()\n",
    "    space['n_neighbors'] = list(range(2, 100))\n",
    "\n",
    "    # Search definition\n",
    "    search = GridSearchCV(model, space, cv=cv_inner, refit=True)\n",
    "\n",
    "    # Search\n",
    "    result = search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    # Model Evaluation\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Store result for the outer one\n",
    "    outer_results.append({'Model': 'KNN', 'MSE': mse, 'R2': r2})\n",
    "\n",
    "    # Plot results\n",
    "    if plots:\n",
    "        num_knn += 1\n",
    "        plt.clf()\n",
    "        plt.plot([min(np.array(y_test)), max(np.array(y_test))], [min(y_pred), max(y_pred)], linestyle='--', color='black',\n",
    "                 label='Perfect Prediction')\n",
    "        plt.scatter(y_test, y_pred, color='blue')\n",
    "        plt.xlabel('Real Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title('Scatter Matrix - KNN')\n",
    "        plt.savefig(f'KNN/{best_model}_{num_knn}.png')\n",
    "\n",
    "    # Report progress\n",
    "    print('- mse=%.3f,r2=%.3f, K_neightbours=%s' % (mse, r2, result.best_params_))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b1ea033c3df4290"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Summarize the estimated performance of the model\n",
    "mse_values = [item['MSE'] for item in outer_results]\n",
    "r2_values = [item['R2'] for item in outer_results]\n",
    "print('MSE: %.3f (%.3f)' % (mean(mse_values), std(mse_values)))\n",
    "print('R2: %.3f (%.3f)' % (mean(r2_values), std(r2_values)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dabb86f5078558bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression Tree\n",
    "Step-by-step Ridge regression process:\n",
    "1. Load the data\n",
    "2. Execute the cross validation method over the data\n",
    "3. Define the model and its space\n",
    "4. Apply the search definition for the cross validation\n",
    "5. Train the models and return the best one\n",
    "6. Test the model and save the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9fcfcd452f86a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Result list\n",
    "outer_results = list()\n",
    "\n",
    "# Enumerate splits\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Outer loop\n",
    "for train, test in cv_outer.split(data.iloc[:, 6:28]):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train, 0:20].astype(float), X.iloc[test, 0:20].astype(float)\n",
    "    a1 = X_train.dtypes\n",
    "    a2 = X_test.dtypes\n",
    "    y_train, y_test = y.iloc[train].astype(float), y.iloc[test].astype(float)\n",
    "    a3 = y_train.dtypes\n",
    "    a4 = y_test.dtypes\n",
    "\n",
    "    # Configure the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "    # Model selection and search space definition\n",
    "    # Model selection\n",
    "    model = DecisionTreeRegressor()\n",
    "    # Search Variables definition\n",
    "    space = dict()\n",
    "    space['max_leaf_nodes'] = list(range(2, 100))\n",
    "    space['min_samples_split'] = list(range(2, 20))\n",
    "\n",
    "    # Search definition\n",
    "    search = GridSearchCV(model, space, cv=cv_inner, refit=True)\n",
    "\n",
    "    # Search\n",
    "    result = search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    # Model Evaluation\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Store result for the outer one\n",
    "    outer_results.append({'Model': 'Regression_Tree', 'MSE': mse, 'R2': r2})\n",
    "\n",
    "    # Plot results\n",
    "    if plots:\n",
    "        fig = plt.figure(figsize=(25, 20))\n",
    "        _ = tree.plot_tree(best_model,\n",
    "                           feature_names=X.iloc[:, 0:20].columns,\n",
    "                           filled=True)\n",
    "        plt.savefig(f'RegressTree/{best_model}.png')\n",
    "\n",
    "    # Report progress\n",
    "    print('- mse=%.3f,r2=%.3f, Tree_Params=%s' % (mse, r2, result.best_params_))\n",
    "\n",
    "# Summarize the estimated performance of the model\n",
    "mse_values = [item['MSE'] for item in outer_results]\n",
    "r2_values = [item['R2'] for item in outer_results]\n",
    "print('MSE: %.3f (%.3f)' % (mean(mse_values), std(mse_values)))\n",
    "print('R2: %.3f (%.3f)' % (mean(r2_values), std(r2_values)))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6720b43bafdb695d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
